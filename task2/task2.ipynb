{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing how the data set is split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(\"./drug200.csv\")\n",
    "dataset['Drug'].value_counts().plot(kind='bar')\n",
    "plt.savefig(\"drugset.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanitizing the data such that both ordinal and categorical features are converted to numerical\n",
    "\n",
    "### The female column is dropped to prevent co-linearity (male explains male/female already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  BP  Cholesterol  Na_to_K   Drug  Sex_M\n",
      "0     23   3            3   25.355  drugY      0\n",
      "1     47   1            3   13.093  drugC      1\n",
      "2     47   1            3   10.114  drugC      1\n",
      "3     28   2            3    7.798  drugX      0\n",
      "4     61   1            3   18.043  drugY      0\n",
      "..   ...  ..          ...      ...    ...    ...\n",
      "195   56   1            3   11.567  drugC      0\n",
      "196   16   1            3   12.006  drugC      1\n",
      "197   52   2            3    9.894  drugX      1\n",
      "198   23   2            2   14.020  drugX      1\n",
      "199   40   1            2   11.349  drugX      0\n",
      "\n",
      "[200 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#sanitizing the ordinal and categorical data into numerical, drop column female to prevent co-linearity\n",
    "\n",
    "drugsData = pd.DataFrame(dataset)\n",
    "\n",
    "ordinalMap = {\n",
    "    \"HIGH\":3,\n",
    "    \"NORMAL\":2,\n",
    "    \"LOW\":1\n",
    "}\n",
    "\n",
    "#mapping ordinal values to numerical\n",
    "drugsData['BP'] = drugsData['BP'].map(ordinalMap)\n",
    "drugsData['Cholesterol'] = drugsData['Cholesterol'].map(ordinalMap)\n",
    "\n",
    "#categorical to numerical through 'get_dummies' method\n",
    "dataset_processed = pd.get_dummies(drugsData, columns=['Sex'])\n",
    "\n",
    "dataset_final = dataset_processed.drop(['Sex_F'], axis ='columns')\n",
    "print(dataset_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data into a training and set (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dataset_final.drop(['Drug'], axis = 'columns')\n",
    "Y = dataset_final['Drug']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing all classification models and training them (6 models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model 1: Gaussian Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_NB = GaussianNB()\n",
    "clf_NB.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model 2: Base Decision Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_DT.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model 3: Top Decision Tree (with parameters)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyper_params1 = {\n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_depth': [3,4],\n",
    "    'min_samples_split': [2,3,4]}\n",
    "\n",
    "clf_TDT = GridSearchCV(DecisionTreeClassifier(), hyper_params1, cv=5)\n",
    "clf_TDT.fit(X_train, Y_train)\n",
    "clf_TDT.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model 4: Perceptron\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf_P = Perceptron()\n",
    "clf_P.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangk\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model 5: Base Multi-Layered Perceptron\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf_MLP = MLPClassifier()\n",
    "clf_MLP.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangk\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', hidden_layer_sizes=(30, 50))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model 6: Top Multi-Layered Perceptron\n",
    "\n",
    "hyper_params2 = {\n",
    "    'hidden_layer_sizes': [(30,50),(10,10,10)],\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "}\n",
    "\n",
    "clf_TMLP = GridSearchCV(MLPClassifier(), hyper_params2, n_jobs=10, cv=3)\n",
    "clf_TMLP.fit(X_train, Y_train)\n",
    "clf_TMLP.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis & output of all required test statistics, averages, standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './task2/drug-performance.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_65000/130061876.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#confusion matrices and test statistics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./task2/drug-performance.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n\\n(a) The model is: Naive Bayes Classifier'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n(b) The confusion matrix is:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './task2/drug-performance.txt'"
     ]
    }
   ],
   "source": [
    "#Analysis\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import statistics\n",
    "\n",
    "target_names = ['Age', 'BP', 'Cholesterol', 'Na_to_k', 'Sex']\n",
    "\n",
    "#confusion matrices and test statistics\n",
    "with open('./drug-performance.txt', 'w+') as f:\n",
    "    f.write('\\n\\n(a) The model is: Naive Bayes Classifier')\n",
    "    f.write('\\n(b) The confusion matrix is:')\n",
    "    f.write('\\n'+ np.array2string(confusion_matrix(Y_test, clf_NB.predict(X_test))))\n",
    "    f.write('\\n(c) & (d) The test statistics are:')\n",
    "    f.write(classification_report(Y_test, clf_NB.predict(X_test)))\n",
    "\n",
    "    f.write('\\n\\n(a) The model is: Base Decision Tree')\n",
    "    f.write('\\n(b) The confusion matrix is:')\n",
    "    f.write('\\n'+ np.array2string(confusion_matrix(Y_test, clf_DT.predict(X_test))))\n",
    "    f.write('\\n(c) & (d) The test statistics are:')\n",
    "    f.write(classification_report(Y_test, clf_DT.predict(X_test)))\n",
    "\n",
    "    f.write('\\n\\n(a) The model is: Top Decision Tree and the paramters changed are '+str(clf_TDT.best_estimator_))\n",
    "    f.write('\\n(b) The confusion matrix is:')\n",
    "    f.write('\\n'+ np.array2string(confusion_matrix(Y_test, clf_TDT.predict(X_test))))\n",
    "    f.write('\\n(c) & (d) The test statistics are:')\n",
    "    f.write(classification_report(Y_test, clf_TDT.predict(X_test)))\n",
    "\n",
    "    f.write('\\n\\n(a) The model is: Perceptron')\n",
    "    f.write('\\n(b) The confusion matrix is:')\n",
    "    f.write('\\n'+ np.array2string(confusion_matrix(Y_test, clf_P.predict(X_test))))\n",
    "    f.write('\\n(c) & (d) The test statistics are:')\n",
    "    f.write(classification_report(Y_test, clf_P.predict(X_test)))\n",
    "\n",
    "    f.write('\\n\\n(a) The model is: Base MLP')\n",
    "    f.write('\\n(b) The confusion matrix is:')\n",
    "    f.write('\\n'+ np.array2string(confusion_matrix(Y_test, clf_MLP.predict(X_test))))\n",
    "    f.write('\\n(c) & (d) The test statistics are:')\n",
    "    f.write(classification_report(Y_test, clf_MLP.predict(X_test)))\n",
    "\n",
    "    f.write('\\n\\n(a) The model is: Top MLP and the paramters changed are '+str(clf_TMLP.best_estimator_))\n",
    "    f.write('\\n(b) The confusion matrix is:')\n",
    "    f.write('\\n'+ np.array2string(confusion_matrix(Y_test, clf_TMLP.predict(X_test))))\n",
    "    f.write('\\n(c) & (d) The test statistics are:')\n",
    "    f.write(classification_report(Y_test, clf_TMLP.predict(X_test)))\n",
    "\n",
    "    f.write('\\n\\n----------------------------------------------------TRIAL RUNS----------------------------------------------------')\n",
    "\n",
    "    num_iterations = 10\n",
    "\n",
    "    #declare the variables to hold the sum for the average and the list for the SD calculations\n",
    "    sum_accuracy_NB = 0.0;  sumM_f1_NB = 0.0; sumW_f1_NB = 0.0\n",
    "    sum_accuracy_DT = 0.0;  sumM_f1_DT = 0.0; sumW_f1_DT = 0.0\n",
    "    sum_accuracy_TDT = 0.0;  sumM_f1_TDT = 0.0; sumW_f1_TDT = 0.0\n",
    "    sum_accuracy_P = 0.0;  sumM_f1_P = 0.0; sumW_f1_P = 0.0\n",
    "    sum_accuracy_MLP = 0.0;  sumM_f1_MLP = 0.0; sumW_f1_MLP = 0.0\n",
    "    sum_accuracy_TMLP = 0.0;  sumM_f1_TMLP = 0.0; sumW_f1_TMLP = 0.0\n",
    "\n",
    "    list_accuracy_NB = []; list_mf1_NB = []; list_wf1_NB =[]\n",
    "    list_accuracy_DT = []; list_mf1_DT = []; list_wf1_DT =[]\n",
    "    list_accuracy_TDT = []; list_mf1_TDT = []; list_wf1_TDT =[]\n",
    "    list_accuracy_P = []; list_mf1_P = []; list_wf1_P =[]\n",
    "    list_accuracy_MLP = []; list_mf1_MLP = []; list_wf1_MLP =[]\n",
    "    list_accuracy_TMLP = []; list_mf1_TMLP = []; list_wf1_TMLP =[]\n",
    "\n",
    "    #we iterate through the experiment 10 times, recording test statistics in a list to do average/SD calculations, we also display the classification report for each trial\n",
    "    for i in range(num_iterations):\n",
    "\n",
    "      clf_NB.fit(X_train, Y_train)\n",
    "      clf_DT.fit(X_train, Y_train)\n",
    "      clf_TDT.fit(X_train, Y_train)\n",
    "      clf_P.fit(X_train, Y_train)\n",
    "      clf_MLP.fit(X_train, Y_train)\n",
    "      clf_TMLP.fit(X_train, Y_train)\n",
    "\n",
    "      sum_accuracy_NB += float(accuracy_score(Y_test, clf_NB.predict(X_test)))\n",
    "      sumM_f1_NB += float(f1_score(Y_test, clf_NB.predict(X_test), average = 'macro'))\n",
    "      sumW_f1_NB += float(f1_score(Y_test, clf_NB.predict(X_test), average = 'weighted'))\n",
    "      list_accuracy_NB.append(accuracy_score(Y_test, clf_NB.predict(X_test)))\n",
    "      list_mf1_NB.append(f1_score(Y_test, clf_NB.predict(X_test), average = 'macro'))\n",
    "      list_wf1_NB.append(f1_score(Y_test, clf_NB.predict(X_test), average = 'weighted'))\n",
    "\n",
    "      sum_accuracy_DT += float(accuracy_score(Y_test, clf_DT.predict(X_test)))\n",
    "      sumM_f1_DT += float(f1_score(Y_test, clf_DT.predict(X_test), average = 'macro'))\n",
    "      sumW_f1_DT += float(f1_score(Y_test, clf_DT.predict(X_test), average = 'weighted'))\n",
    "      list_accuracy_DT.append(accuracy_score(Y_test, clf_DT.predict(X_test)))\n",
    "      list_mf1_DT.append(f1_score(Y_test, clf_DT.predict(X_test), average = 'macro'))\n",
    "      list_wf1_DT.append(f1_score(Y_test, clf_DT.predict(X_test), average = 'weighted'))\n",
    "\n",
    "      sum_accuracy_TDT += float(accuracy_score(Y_test, clf_TDT.predict(X_test)))\n",
    "      sumM_f1_TDT += float(f1_score(Y_test, clf_TDT.predict(X_test), average = 'macro'))\n",
    "      sumW_f1_TDT += float(f1_score(Y_test, clf_TDT.predict(X_test), average = 'weighted'))\n",
    "      list_accuracy_TDT.append(accuracy_score(Y_test, clf_TDT.predict(X_test)))\n",
    "      list_mf1_TDT.append(f1_score(Y_test, clf_TDT.predict(X_test), average = 'macro'))\n",
    "      list_wf1_TDT.append(f1_score(Y_test, clf_TDT.predict(X_test), average = 'weighted'))\n",
    "\n",
    "      sum_accuracy_P += float(accuracy_score(Y_test, clf_P.predict(X_test)))\n",
    "      sumM_f1_P += float(f1_score(Y_test, clf_P.predict(X_test), average = 'macro'))\n",
    "      sumW_f1_P += float(f1_score(Y_test, clf_P.predict(X_test), average = 'weighted'))\n",
    "      list_accuracy_P.append(accuracy_score(Y_test, clf_P.predict(X_test)))\n",
    "      list_mf1_P.append(f1_score(Y_test, clf_P.predict(X_test), average = 'macro'))\n",
    "      list_wf1_P.append(f1_score(Y_test, clf_P.predict(X_test), average = 'weighted'))\n",
    "\n",
    "      sum_accuracy_MLP += float(accuracy_score(Y_test, clf_MLP.predict(X_test)))\n",
    "      sumM_f1_MLP += float(f1_score(Y_test, clf_MLP.predict(X_test), average = 'macro'))\n",
    "      sumW_f1_MLP += float(f1_score(Y_test, clf_MLP.predict(X_test), average = 'weighted'))\n",
    "      list_accuracy_MLP.append(accuracy_score(Y_test, clf_MLP.predict(X_test)))\n",
    "      list_mf1_MLP.append(f1_score(Y_test, clf_MLP.predict(X_test), average = 'macro'))\n",
    "      list_wf1_MLP.append(f1_score(Y_test, clf_MLP.predict(X_test), average = 'weighted'))\n",
    "\n",
    "      sum_accuracy_TMLP += float(accuracy_score(Y_test, clf_TMLP.predict(X_test)))\n",
    "      sumM_f1_TMLP += float(f1_score(Y_test, clf_TMLP.predict(X_test), average = 'macro'))\n",
    "      sumW_f1_TMLP += float(f1_score(Y_test, clf_TMLP.predict(X_test), average = 'weighted'))\n",
    "      list_accuracy_TMLP.append(accuracy_score(Y_test, clf_TMLP.predict(X_test)))\n",
    "      list_mf1_TMLP.append(f1_score(Y_test, clf_TMLP.predict(X_test), average = 'macro'))\n",
    "      list_wf1_TMLP.append(f1_score(Y_test, clf_TMLP.predict(X_test), average = 'weighted'))\n",
    "\n",
    "      f.write('\\n>>>>>trial #' + str(i + 1))\n",
    "      f.write('\\n\\nNaive Bayes')\n",
    "      f.write(classification_report(Y_test, clf_NB.predict(X_test)))\n",
    "      f.write('\\nDecision Tree')\n",
    "      f.write(classification_report(Y_test, clf_DT.predict(X_test)))\n",
    "      f.write('\\nTop Decision Tree')\n",
    "      f.write(classification_report(Y_test, clf_TDT.predict(X_test)))\n",
    "      f.write('\\nPerceptron')\n",
    "      f.write(classification_report(Y_test, clf_P.predict(X_test)))\n",
    "      f.write('\\nMLP')\n",
    "      f.write(classification_report(Y_test, clf_MLP.predict(X_test)))\n",
    "      f.write('\\nTop MLP')\n",
    "      f.write(classification_report(Y_test, clf_TMLP.predict(X_test)))\n",
    "\n",
    "    #write the output for the averages and SD to the file\n",
    "    f.write('\\n\\n----------------------------------------------------NAIVE BAYES----------------------------------------------------')\n",
    "    f.write('\\nThe average accuracy is: '+ str(sum_accuracy_NB / float(num_iterations)))\n",
    "    f.write('\\nThe average macro F1 is: '+ str(sumM_f1_NB / float(num_iterations)))\n",
    "    f.write('\\nThe average weighted F1 is: '+ str(sumW_f1_NB / float(num_iterations)))\n",
    "    f.write('\\nThe SD accuracy is: '+ str(statistics.stdev(list_accuracy_NB)))\n",
    "    f.write('\\nThe SD macro F1 is: '+ str(statistics.stdev(list_mf1_NB)))\n",
    "    f.write('\\nThe SD weighted F1 is: '+ str(statistics.stdev(list_wf1_NB)))\n",
    "\n",
    "    f.write('\\n\\n----------------------------------------------------BASE DECISION TREE----------------------------------------------------')\n",
    "    f.write('\\nThe average accuracy is: '+ str(sum_accuracy_DT / float(num_iterations)))\n",
    "    f.write('\\nThe average macro F1 is: '+ str(sumM_f1_DT / float(num_iterations)))\n",
    "    f.write('\\nThe average weighted F1 is: '+ str(sumW_f1_DT / float(num_iterations)))\n",
    "    f.write('\\nThe SD accuracy is: '+ str(statistics.stdev(list_accuracy_DT)))\n",
    "    f.write('\\nThe SD macro F1 is: '+ str(statistics.stdev(list_mf1_DT)))\n",
    "    f.write('\\nThe SD weighted F1 is: '+ str(statistics.stdev(list_wf1_DT)))\n",
    "\n",
    "    f.write('\\n\\n----------------------------------------------------TOP DECISION TREE----------------------------------------------------')\n",
    "    f.write('\\nThe average accuracy is: '+ str(sum_accuracy_TDT / float(num_iterations)))\n",
    "    f.write('\\nThe average macro F1 is: '+ str(sumM_f1_TDT / float(num_iterations)))\n",
    "    f.write('\\nThe average weighted F1 is: '+ str(sumW_f1_TDT / float(num_iterations)))\n",
    "    f.write('\\nThe SD accuracy is: '+ str(statistics.stdev(list_accuracy_TDT)))\n",
    "    f.write('\\nThe SD macro F1 is: '+ str(statistics.stdev(list_mf1_TDT)))\n",
    "    f.write('\\nThe SD weighted F1 is: '+ str(statistics.stdev(list_wf1_TDT)))\n",
    "\n",
    "    f.write('\\n\\n----------------------------------------------------PERCEPTRON----------------------------------------------------')\n",
    "    f.write('\\nThe average accuracy is: '+ str(sum_accuracy_P / float(num_iterations)))\n",
    "    f.write('\\nThe average macro F1 is: '+ str(sumM_f1_P / float(num_iterations)))\n",
    "    f.write('\\nThe average weighted F1 is: '+ str(sumW_f1_P / float(num_iterations)))\n",
    "    f.write('\\nThe SD accuracy is: '+ str(statistics.stdev(list_accuracy_P)))\n",
    "    f.write('\\nThe SD macro F1 is: '+ str(statistics.stdev(list_mf1_P)))\n",
    "    f.write('\\nThe SD weighted F1 is: '+ str(statistics.stdev(list_wf1_P)))\n",
    "\n",
    "    f.write('\\n\\n----------------------------------------------------BASE MLP----------------------------------------------------')\n",
    "    f.write('\\nThe average accuracy is: '+ str(sum_accuracy_MLP / float(num_iterations)))\n",
    "    f.write('\\nThe average macro F1 is: '+ str(sumM_f1_MLP / float(num_iterations)))\n",
    "    f.write('\\nThe average weighted F1 is: '+ str(sumW_f1_MLP / float(num_iterations)))\n",
    "    f.write('\\nThe SD accuracy is: '+ str(statistics.stdev(list_accuracy_MLP)))\n",
    "    f.write('\\nThe SD macro F1 is: '+ str(statistics.stdev(list_mf1_MLP)))\n",
    "    f.write('\\nThe SD weighted F1 is: '+ str(statistics.stdev(list_wf1_MLP)))\n",
    "\n",
    "    f.write('\\n\\n----------------------------------------------------TOP MLP----------------------------------------------------')\n",
    "    f.write('\\nThe average accuracy is: '+ str(sum_accuracy_TMLP / float(num_iterations)))\n",
    "    f.write('\\nThe average macro F1 is: '+ str(sumM_f1_TMLP / float(num_iterations)))\n",
    "    f.write('\\nThe average weighted F1 is: '+ str(sumW_f1_TMLP / float(num_iterations)))\n",
    "    f.write('\\nThe SD accuracy is: '+ str(statistics.stdev(list_accuracy_TMLP)))\n",
    "    f.write('\\nThe SD macro F1 is: '+ str(statistics.stdev(list_mf1_TMLP)))\n",
    "    f.write('\\nThe SD weighted F1 is: '+ str(statistics.stdev(list_wf1_TMLP)))\n",
    "    f.close"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe44fef87f92f48a3a32707d0df204585f471652bc0ce87358a3ce712bc24db0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
