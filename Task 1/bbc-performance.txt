(a)
*****************************************
Multinomial Naive Bayes classifier, try 1
*****************************************

(b)
[[ 92   1   1   0   2]
 [  0  68   2   0   1]
 [  0   1  80   0   0]
 [  0   0   0 106   0]
 [  2   0   0   0  89]]

(c)
               precision    recall  f1-score   support

     business       0.98      0.96      0.97        96
entertainment       0.97      0.96      0.96        71
     politics       0.96      0.99      0.98        81
        sport       1.00      1.00      1.00       106
         tech       0.97      0.98      0.97        91

     accuracy                           0.98       445
    macro avg       0.98      0.98      0.98       445
 weighted avg       0.98      0.98      0.98       445

(d)
Accuracy Score = 0.9775280898876404
Macro F1 Score = 0.9762494822899507
Weighted F1 Score = 0.9775027910163279

(e)
Prior Probability for each class:
business	 = -1.4585026694608167
entertainment	 = -1.7317960044604979
politics	 = -1.6672574833229268
sport		 = -1.4804815761795922
tech		 = -1.7477963458069388

(f)
Size of vocabulary: 29421 words
(g)
entertainment: 124893
business: 164663
sport: 162953
politics: 185208
tech: 198640

(h)
Word-tokens in the corpus: 836357 words
(i)
entertainment: 17746 words with frequence of zero or, 2.12%
business: 17538 words with frequence of zero or, 2.10%
sport: 18850 words with frequence of zero or, 2.25%
politics: 18201 words with frequence of zero or, 2.18%
tech: 17323 words with frequence of zero or, 2.07%

(j)
There are 10005 words with a frequency of 1 in the corpus or 1.20%
(j)
There are 10005 words with a frequency of 1 in the corpus or 1.20%
(k)
entertainment => the -2.7149437879850633
entertainment => to -3.7617126856825998

business => the -2.722597113359981
business => to -3.477409294065489

sport => the -2.8257787746847027
sport => to -3.541441174105334

politics => the -2.7213559022305507
politics => to -3.429053604052196

tech => the -2.8313071877023757
tech => to -3.435352413042588

(a)
*****************************************
Multinomial Naive Bayes classifier, try 2
*****************************************

(b)
[[ 92   1   1   0   2]
 [  0  68   2   0   1]
 [  0   1  80   0   0]
 [  0   0   0 106   0]
 [  2   0   0   0  89]]

(c)
               precision    recall  f1-score   support

     business       0.98      0.96      0.97        96
entertainment       0.97      0.96      0.96        71
     politics       0.96      0.99      0.98        81
        sport       1.00      1.00      1.00       106
         tech       0.97      0.98      0.97        91

     accuracy                           0.98       445
    macro avg       0.98      0.98      0.98       445
 weighted avg       0.98      0.98      0.98       445

(d)
Accuracy Score = 0.9775280898876404
Macro F1 Score = 0.9762494822899507
Weighted F1 Score = 0.9775027910163279

(e)
Prior Probability for each class:
business	 = -1.4585026694608167
entertainment	 = -1.7317960044604979
politics	 = -1.6672574833229268
sport		 = -1.4804815761795922
tech		 = -1.7477963458069388

(f)
Size of vocabulary: 29421 words
(g)
entertainment: 124893
business: 164663
sport: 162953
politics: 185208
tech: 198640

(h)
Word-tokens in the corpus: 836357 words
(i)
entertainment: 17746 words with frequence of zero or, 2.12%
business: 17538 words with frequence of zero or, 2.10%
sport: 18850 words with frequence of zero or, 2.25%
politics: 18201 words with frequence of zero or, 2.18%
tech: 17323 words with frequence of zero or, 2.07%

(j)
There are 10005 words with a frequency of 1 in the corpus or 1.20%
(j)
There are 10005 words with a frequency of 1 in the corpus or 1.20%
(k)
entertainment => the -2.7149437879850633
entertainment => to -3.7617126856825998

business => the -2.722597113359981
business => to -3.477409294065489

sport => the -2.8257787746847027
sport => to -3.541441174105334

politics => the -2.7213559022305507
politics => to -3.429053604052196

tech => the -2.8313071877023757
tech => to -3.435352413042588

(a)
**************************************************************
Multinomial Naive Bayes classifier, try 3 (smoothing 0.0001
**************************************************************

(b)
[[ 92   1   0   0   3]
 [  0  68   2   0   1]
 [  3   0  78   0   0]
 [  0   0   0 106   0]
 [  3   1   0   0  87]]

(c)
               precision    recall  f1-score   support

     business       0.94      0.96      0.95        96
entertainment       0.97      0.96      0.96        71
     politics       0.97      0.96      0.97        81
        sport       1.00      1.00      1.00       106
         tech       0.96      0.96      0.96        91

     accuracy                           0.97       445
    macro avg       0.97      0.97      0.97       445
 weighted avg       0.97      0.97      0.97       445

(d)
Accuracy Score = 0.9685393258426966
Macro F1 Score = 0.9675961341524918
Weighted F1 Score = 0.9685804223482879

(e)
Prior Probability for each class:
business	 = -1.4585026694608167
entertainment	 = -1.7317960044604979
politics	 = -1.6672574833229268
sport		 = -1.4804815761795922
tech		 = -1.7477963458069388

(f)
Size of vocabulary: 29421 words
(g)
entertainment: 124893
business: 164663
sport: 162953
politics: 185208
tech: 198640

(h)
Word-tokens in the corpus: 836357 words
(i)
entertainment: 17746 words with frequence of zero or, 2.12%
business: 17538 words with frequence of zero or, 2.10%
sport: 18850 words with frequence of zero or, 2.25%
politics: 18201 words with frequence of zero or, 2.18%
tech: 17323 words with frequence of zero or, 2.07%

(j)
There are 10005 words with a frequency of 1 in the corpus or 1.20%
(j)
There are 10005 words with a frequency of 1 in the corpus or 1.20%
(k)
entertainment => the -2.7149437879850633
entertainment => to -3.7617126856825998

business => the -2.722597113359981
business => to -3.477409294065489

sport => the -2.8257787746847027
sport => to -3.541441174105334

politics => the -2.7213559022305507
politics => to -3.429053604052196

tech => the -2.8313071877023757
tech => to -3.435352413042588

(a)
**************************************************************
Multinomial Naive Bayes classifier, try 4 (smoothing 0.9
**************************************************************

(b)
[[ 92   1   1   0   2]
 [  0  68   2   0   1]
 [  0   1  80   0   0]
 [  0   0   0 106   0]
 [  2   0   0   0  89]]

(c)
               precision    recall  f1-score   support

     business       0.98      0.96      0.97        96
entertainment       0.97      0.96      0.96        71
     politics       0.96      0.99      0.98        81
        sport       1.00      1.00      1.00       106
         tech       0.97      0.98      0.97        91

     accuracy                           0.98       445
    macro avg       0.98      0.98      0.98       445
 weighted avg       0.98      0.98      0.98       445

(d)
Accuracy Score = 0.9775280898876404
Macro F1 Score = 0.9762494822899507
Weighted F1 Score = 0.9775027910163279

(e)
Prior Probability for each class:
business	 = -1.4585026694608167
entertainment	 = -1.7317960044604979
politics	 = -1.6672574833229268
sport		 = -1.4804815761795922
tech		 = -1.7477963458069388

(f)
Size of vocabulary: 29421 words
(g)
entertainment: 124893
business: 164663
sport: 162953
politics: 185208
tech: 198640

(h)
Word-tokens in the corpus: 836357 words
(i)
entertainment: 17746 words with frequence of zero or, 2.12%
business: 17538 words with frequence of zero or, 2.10%
sport: 18850 words with frequence of zero or, 2.25%
politics: 18201 words with frequence of zero or, 2.18%
tech: 17323 words with frequence of zero or, 2.07%

(j)
There are 10005 words with a frequency of 1 in the corpus or 1.20%
(j)
There are 10005 words with a frequency of 1 in the corpus or 1.20%
(k)
entertainment => the -2.7149437879850633
entertainment => to -3.7617126856825998

business => the -2.722597113359981
business => to -3.477409294065489

sport => the -2.8257787746847027
sport => to -3.541441174105334

politics => the -2.7213559022305507
politics => to -3.429053604052196

tech => the -2.8313071877023757
tech => to -3.435352413042588

